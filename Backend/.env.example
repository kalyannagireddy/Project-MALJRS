# Ollama Configuration
# Copy this file to .env and update with your values

# Model configuration
OLLAMA_MODEL=gpt-oss:120b

# Base URL for Ollama API
# For cloud: https://ollama.com
# For local: http://localhost:11434
OLLAMA_BASE_URL=https://ollama.com

# Temperature for model responses (0.0 to 1.0)
TEMPERATURE=0.1

# API key for Ollama Cloud (required for cloud API)
# Leave empty for local instances
OLLAMA_API_KEY=your-api-key-here
